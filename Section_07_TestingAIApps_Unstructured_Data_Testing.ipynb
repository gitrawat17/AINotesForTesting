{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji_U-yfC04xW",
        "outputId": "e3d7f86a-00bc-48a0-bfbb-aed005a2bc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 pandas pypdf2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Text from PDF**\n",
        "\n",
        "For the purpose of validation, we need to extract the raw text from the PDF and convert it into a structured form (e.g., tables, sections). Here's how you can extract text from a PDF using PyPDF2."
      ],
      "metadata": {
        "id": "FcWuzbu72ulg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "pdf_path = '/content/test_data_validation_pdf.pdf'\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "print(pdf_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fj_In6l2jzd",
        "outputId": "6e50973e-ff14-4cbf-8b08-5a520d67b483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test PDF for Data Validation\n",
            "\n",
            "Section 1: Descriptions (Raw Text Validation)\n",
            "This section includes general information about a fictional product. The product was launched in 2023, with\n",
            "an expected growth rate of 10% per annum. Further insights include a focus on developing AI technologies\n",
            "by 2025.\n",
            "\n",
            "Section 2: Table (Tabular Data Validation)\n",
            "Name Date of Birth Email\n",
            "John Doe 1980-05-12 john.doe@email.com\n",
            "Jane Smith 1990-07-23 jane.smith.email.com\n",
            "Mike Brown 1975-11-05 mike.brown@email.com\n",
            "\n",
            "Section 3: Regular Expression Validation\n",
            "This section includes examples of text that should match specific patterns.\n",
            "Contact: (555)-123-4567. Expected date: 12-12-2024.\n",
            "Please validate the date formats and phone number patterns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a structured PDF, such as a requirements document, we might want to check whether certain fields have consistent values (e.g., all requirement IDs are unique or all dates are in the correct format)."
      ],
      "metadata": {
        "id": "99VcoGcT5rTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def check_for_sections(text, section_names):\n",
        "    \"\"\"\n",
        "    Check if specific sections (e.g., \"Requirements\", \"Specifications\") exist in the PDF text.\n",
        "    :param text: The extracted text from the PDF.\n",
        "    :param section_names: List of sections to look for.\n",
        "    \"\"\"\n",
        "    missing_sections = []\n",
        "    for section in section_names:\n",
        "        if re.search(section, text, re.IGNORECASE) is None:\n",
        "            missing_sections.append(section)\n",
        "\n",
        "    if missing_sections:\n",
        "        print(f\"Error: The following sections are missing: {', '.join(missing_sections)}\")\n",
        "    else:\n",
        "        print(\"All required sections are present.\")\n",
        "\n",
        "# Check for key sections in the PDF\n",
        "sections_to_validate = [\"Requirements\", \"Section 2: Table\", \"10%\"]\n",
        "check_for_sections(pdf_text, sections_to_validate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYkFclY84_g3",
        "outputId": "97a0a970-e3b0-43aa-95cc-889598628ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The following sections are missing: Requirements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def validate_consistency_of_ids(text):\n",
        "    \"\"\"\n",
        "    Validate the uniqueness and consistency of IDs in the text.\n",
        "    :param text: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    ids = re.findall(r\"\\bSection \\d+\\b\", text)  # Example: Look for pattern like REQ-123\n",
        "    if len(ids) != len(set(ids)):\n",
        "        print(\"Error: Duplicate IDs found.\")\n",
        "    else:\n",
        "        print(\"All IDs are unique.\")\n",
        "\n",
        "# Validate consistency of IDs\n",
        "validate_consistency_of_ids(pdf_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_tP9dzj5VQ6",
        "outputId": "5e8fc9d6-eacf-403d-cfec-0c9eb80093c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All IDs are unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the PDF contains tables that need to be extracted, validated, and processed further, we need to use a more advanced method. For example, we could use libraries like tabula-py to extract tabular data."
      ],
      "metadata": {
        "id": "wubCqT6s5kEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I72r68e75kkb",
        "outputId": "e92efd18-6afc-4db1-e614-256730bfc405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.9.3-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.26.4)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Downloading tabula_py-2.9.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tabula\n",
        "\n",
        "def extract_tables_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract tables from a PDF using tabula.\n",
        "    :param pdf_path: Path to the PDF file.\n",
        "    :return: List of DataFrames representing tables in the PDF.\n",
        "    \"\"\"\n",
        "    tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
        "    return tables\n",
        "\n",
        "# Extract tables from the PDF\n",
        "tables = extract_tables_from_pdf(pdf_path)\n",
        "\n",
        "# Show first table\n",
        "if tables:\n",
        "    print(tables[0].head())\n",
        "else:\n",
        "    print(\"No tables found in the PDF.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceGcR5gB5xce",
        "outputId": "a9ab5132-1999-453a-c118-f7b983225a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
            "WARNING:tabula.backend:No module named 'jpype'\n",
            "WARNING:tabula.backend:Got stderr: Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
            "WARNING: New fonts found, font cache will be re-built\n",
            "Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Building on-disk font cache, this may take a while\n",
            "Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Finished building on-disk font cache, found 17 fonts\n",
            "Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Sep 10, 2024 7:47:48 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for .notdef (10) in font Helvetica-Bold\n",
            "Sep 10, 2024 7:47:49 AM org.apache.pdfbox.rendering.Type1Glyph2D getPathForCharacterCode\n",
            "WARNING: No glyph for code 10 (.notdef) in font Helvetica-Bold\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Name Date of Birth                 Email\n",
            "0    John Doe    1980-05-12    john.doe@email.com\n",
            "1  Jane Smith    1990-07-23  jane.smith.email.com\n",
            "2  Mike Brown    1975-11-05  mike.brown@email.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data is extracted, you can run more comprehensive data validation tests, such as:\n",
        "\n",
        "Missing value checks: Ensure required fields are not empty.\n",
        "Data type validation: Validate that the extracted values conform to expected data types.\n",
        "Outlier detection: Use statistical methods to find anomalies in the data."
      ],
      "metadata": {
        "id": "Qq-J4fz851vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Step 1: Extract Text Data from the PDF\n",
        "def extract_pdf_text(pdf_file):\n",
        "    reader = PdfReader(pdf_file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Step 2: Raw Text Validation\n",
        "def validate_raw_text(text):\n",
        "    issues = []\n",
        "\n",
        "    # Validate that the year 2023 is mentioned\n",
        "    if \"2023\" not in text:\n",
        "        issues.append(\"Year 2023 not mentioned in the text.\")\n",
        "\n",
        "    # Validate the growth rate is mentioned\n",
        "    if \"10%\" not in text:\n",
        "        issues.append(\"Growth rate of 10% not mentioned in the text.\")\n",
        "\n",
        "    return issues if issues else \"Raw text validation passed.\"\n",
        "\n",
        "# Step 3: Tabular Data Validation (Check Email and Date of Birth)\n",
        "def validate_tabular_data(text):\n",
        "    issues = []\n",
        "\n",
        "    # Validate email addresses\n",
        "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    invalid_emails = [email for email in emails if not re.match(r\"[^@]+@[^@]+\\.[^@]+\", email)]\n",
        "\n",
        "    if invalid_emails:\n",
        "        issues.append(f\"Invalid email addresses found: {invalid_emails}\")\n",
        "\n",
        "    # Validate dates in format YYYY-MM-DD\n",
        "    dates = re.findall(r'\\d{4}-\\d{2}-\\d{2}', text)\n",
        "    if not dates:\n",
        "        issues.append(\"No valid dates of birth found in the table.\")\n",
        "\n",
        "    return issues if issues else \"Tabular data validation passed.\"\n",
        "\n",
        "# Step 4: Regular Expression Validation (Check phone number and date format)\n",
        "def validate_regex_patterns(text):\n",
        "    issues = []\n",
        "\n",
        "    # Validate phone numbers (format: (555)-123-4567)\n",
        "    phone_numbers = re.findall(r'\\(\\d{3}\\)-\\d{3}-\\d{4}', text)\n",
        "    if not phone_numbers:\n",
        "        issues.append(\"No valid phone numbers found in the format (555)-123-4567.\")\n",
        "\n",
        "    # Validate expected date format (format: dd-mm-yyyy)\n",
        "    expected_dates = re.findall(r'\\d{2}-\\d{2}-\\d{4}', text)\n",
        "    if not expected_dates:\n",
        "        issues.append(\"No valid expected dates found in the format dd-mm-yyyy.\")\n",
        "\n",
        "    return issues if issues else \"Regex pattern validation passed.\"\n",
        "\n",
        "# Main function to validate the PDF\n",
        "def validate_pdf(pdf_file):\n",
        "    text = extract_pdf_text(pdf_file)\n",
        "\n",
        "    print(\"\\nRaw Text Validation:\")\n",
        "    print(validate_raw_text(text))\n",
        "\n",
        "    print(\"\\nTabular Data Validation:\")\n",
        "    print(validate_tabular_data(text))\n",
        "\n",
        "    print(\"\\nRegex Pattern Validation:\")\n",
        "    print(validate_regex_patterns(text))\n",
        "\n",
        "\n",
        "# Run the validation on the provided PDF\n",
        "pdf_file_path = \"/content/test_data_validation_pdf.pdf\"  # Replace with actual PDF path\n",
        "validate_pdf(pdf_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jRev87657QE",
        "outputId": "4094cd4f-7c79-44fa-df91-4cc094016957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw Text Validation:\n",
            "Raw text validation passed.\n",
            "\n",
            "Tabular Data Validation:\n",
            "Tabular data validation passed.\n",
            "\n",
            "Regex Pattern Validation:\n",
            "Regex pattern validation passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jr3sHNp27Wz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement image data validation using a small image dataset. I'll use a subset of the **CIFAR-10** dataset, which is available through the `torchvision` package. We'll load a few images, apply basic validation (like file type, size, and color mode checks), and show how to implement this in code.\n",
        "\n",
        "### Steps:\n",
        "1. Install required libraries.\n",
        "2. Download a subset of the CIFAR-10 dataset.\n",
        "3. Apply the validation functions for file types, dimensions, and color modes.\n",
        "\n",
        "### 1. Install Required Libraries\n",
        "\n",
        "```bash\n",
        "!pip install pillow\n",
        "!pip install torchvision\n",
        "```\n",
        "\n",
        "### 2. Download and Load the CIFAR-10 Dataset\n",
        "\n",
        "```python\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Create a directory to store the images\n",
        "os.makedirs('cifar10_images', exist_ok=True)\n",
        "\n",
        "# Define the transform to convert images to tensor and save them\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Download and load the CIFAR-10 training dataset (first 10 images)\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Save the first 10 images from the dataset\n",
        "for i in range(10):\n",
        "    image, label = dataset[i]\n",
        "    save_image(image, f'cifar10_images/image_{i}.png')\n",
        "```\n",
        "\n",
        "### 3. Implement Image Validation Functions\n",
        "\n",
        "We'll use the `Pillow` library to handle image operations and run validations similar to what we outlined before.\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your image dataset folder\n",
        "IMAGE_DIR = \"cifar10_images\"\n",
        "\n",
        "# Step 1: File Type Validation\n",
        "def validate_file_types(image_dir, valid_extensions=['.jpg', '.png']):\n",
        "    invalid_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        ext = os.path.splitext(filename)[-1].lower()\n",
        "        if ext not in valid_extensions:\n",
        "            invalid_files.append(filename)\n",
        "    if invalid_files:\n",
        "        print(f\"Invalid file types found: {invalid_files}\")\n",
        "    else:\n",
        "        print(\"All files have valid image extensions.\")\n",
        "\n",
        "# Step 2: Corrupted File Detection\n",
        "def check_corrupted_images(image_dir):\n",
        "    corrupted_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Check if image can be opened\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            corrupted_files.append(filename)\n",
        "    if corrupted_files:\n",
        "        print(f\"Corrupted files found: {corrupted_files}\")\n",
        "    else:\n",
        "        print(\"No corrupted files found.\")\n",
        "\n",
        "# Step 3: Dimension and Aspect Ratio Check\n",
        "def validate_image_dimensions(image_dir, expected_size=(32, 32)):\n",
        "    incorrect_size_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.size != expected_size:\n",
        "                    incorrect_size_files.append((filename, img.size))\n",
        "        except Exception as e:\n",
        "            continue  # Skip files that can't be opened\n",
        "    if incorrect_size_files:\n",
        "        print(f\"Images with incorrect dimensions found: {incorrect_size_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected dimensions of {expected_size}.\")\n",
        "\n",
        "# Step 4: Color Mode Verification (RGB or Grayscale)\n",
        "def validate_color_mode(image_dir, expected_mode='RGB'):\n",
        "    incorrect_mode_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.mode != expected_mode:\n",
        "                    incorrect_mode_files.append((filename, img.mode))\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    if incorrect_mode_files:\n",
        "        print(f\"Images with incorrect color mode found: {incorrect_mode_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected color mode: {expected_mode}.\")\n",
        "\n",
        "# Step 5: Outlier Detection (by file size)\n",
        "def detect_outliers_by_size(image_dir, threshold_factor=2):\n",
        "    sizes = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        sizes.append(os.path.getsize(file_path))\n",
        "    \n",
        "    avg_size = np.mean(sizes)\n",
        "    std_dev = np.std(sizes)\n",
        "    \n",
        "    outliers = [(filename, size) for filename, size in zip(os.listdir(image_dir), sizes) if abs(size - avg_size) > threshold_factor * std_dev]\n",
        "    if outliers:\n",
        "        print(f\"Outliers found based on size: {outliers}\")\n",
        "    else:\n",
        "        print(\"No outliers detected based on file size.\")\n",
        "\n",
        "# Main function to perform all validation steps\n",
        "def validate_image_dataset(image_dir):\n",
        "    print(\"Starting image dataset validation...\\n\")\n",
        "    \n",
        "    # Step 1: Validate file types\n",
        "    print(\"Validating file types...\")\n",
        "    validate_file_types(image_dir)\n",
        "    \n",
        "    # Step 2: Check for corrupted files\n",
        "    print(\"\\nChecking for corrupted files...\")\n",
        "    check_corrupted_images(image_dir)\n",
        "    \n",
        "    # Step 3: Validate image dimensions\n",
        "    print(\"\\nValidating image dimensions...\")\n",
        "    validate_image_dimensions(image_dir, expected_size=(32, 32))\n",
        "    \n",
        "    # Step 4: Validate color mode\n",
        "    print(\"\\nValidating image color mode...\")\n",
        "    validate_color_mode(image_dir, expected_mode='RGB')\n",
        "    \n",
        "    # Step 5: Detect outliers by file size\n",
        "    print(\"\\nDetecting outliers by file size...\")\n",
        "    detect_outliers_by_size(image_dir)\n",
        "\n",
        "# Run the validation on your image dataset\n",
        "validate_image_dataset(IMAGE_DIR)\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **File Type Validation**:\n",
        "   - Checks if all files in the dataset have valid image extensions like `.jpg` or `.png`.\n",
        "\n",
        "2. **Corrupted File Detection**:\n",
        "   - Opens each image to check if it can be opened or if it's corrupted.\n",
        "\n",
        "3. **Dimension Check**:\n",
        "   - Validates that all images have the correct dimensions (32x32 in the case of CIFAR-10).\n",
        "\n",
        "4. **Color Mode Verification**:\n",
        "   - Ensures all images are in RGB mode.\n",
        "\n",
        "5. **Outlier Detection by File Size**:\n",
        "   - Detects images whose file sizes deviate significantly from the average.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This code provides a comprehensive validation for a small image dataset like CIFAR-10, ensuring that the data is clean and ready for use in AI model training."
      ],
      "metadata": {
        "id": "Wv4ogifw_kIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow\n",
        "!pip install torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iViWN6lp_o0A",
        "outputId": "04c68445-5a51-4053-b183-d67856d56126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Create a directory to store the images\n",
        "os.makedirs('cifar10_images', exist_ok=True)\n",
        "\n",
        "# Define the transform to convert images to tensor and save them\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Download and load the CIFAR-10 training dataset (first 10 images)\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Save the first 10 images from the dataset\n",
        "for i in range(10):\n",
        "    image, label = dataset[i]\n",
        "    save_image(image, f'cifar10_images/image_{i}.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kId_lOAk_uKZ",
        "outputId": "9f178c74-14d2-447e-f753-362a55d36461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 16041015.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your image dataset folder\n",
        "IMAGE_DIR = \"cifar10_images\"\n",
        "\n",
        "# Step 1: File Type Validation\n",
        "def validate_file_types(image_dir, valid_extensions=['.jpg', '.png']):\n",
        "    invalid_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        ext = os.path.splitext(filename)[-1].lower()\n",
        "        if ext not in valid_extensions:\n",
        "            invalid_files.append(filename)\n",
        "    if invalid_files:\n",
        "        print(f\"Invalid file types found: {invalid_files}\")\n",
        "    else:\n",
        "        print(\"All files have valid image extensions.\")\n",
        "\n",
        "# Step 2: Corrupted File Detection\n",
        "def check_corrupted_images(image_dir):\n",
        "    corrupted_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Check if image can be opened\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            corrupted_files.append(filename)\n",
        "    if corrupted_files:\n",
        "        print(f\"Corrupted files found: {corrupted_files}\")\n",
        "    else:\n",
        "        print(\"No corrupted files found.\")\n",
        "\n",
        "# Step 3: Dimension and Aspect Ratio Check\n",
        "def validate_image_dimensions(image_dir, expected_size=(32, 32)):\n",
        "    incorrect_size_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.size != expected_size:\n",
        "                    incorrect_size_files.append((filename, img.size))\n",
        "        except Exception as e:\n",
        "            continue  # Skip files that can't be opened\n",
        "    if incorrect_size_files:\n",
        "        print(f\"Images with incorrect dimensions found: {incorrect_size_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected dimensions of {expected_size}.\")\n",
        "\n",
        "# Step 4: Color Mode Verification (RGB or Grayscale)\n",
        "def validate_color_mode(image_dir, expected_mode='RGB'):\n",
        "    incorrect_mode_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.mode != expected_mode:\n",
        "                    incorrect_mode_files.append((filename, img.mode))\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    if incorrect_mode_files:\n",
        "        print(f\"Images with incorrect color mode found: {incorrect_mode_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected color mode: {expected_mode}.\")\n",
        "\n",
        "# Step 5: Outlier Detection (by file size)\n",
        "def detect_outliers_by_size(image_dir, threshold_factor=2):\n",
        "    sizes = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        sizes.append(os.path.getsize(file_path))\n",
        "\n",
        "    avg_size = np.mean(sizes)\n",
        "    std_dev = np.std(sizes)\n",
        "\n",
        "    outliers = [(filename, size) for filename, size in zip(os.listdir(image_dir), sizes) if abs(size - avg_size) > threshold_factor * std_dev]\n",
        "    if outliers:\n",
        "        print(f\"Outliers found based on size: {outliers}\")\n",
        "    else:\n",
        "        print(\"No outliers detected based on file size.\")\n",
        "\n",
        "# Main function to perform all validation steps\n",
        "def validate_image_dataset(image_dir):\n",
        "    print(\"Starting image dataset validation...\\n\")\n",
        "\n",
        "    # Step 1: Validate file types\n",
        "    print(\"Validating file types...\")\n",
        "    validate_file_types(image_dir)\n",
        "\n",
        "    # Step 2: Check for corrupted files\n",
        "    print(\"\\nChecking for corrupted files...\")\n",
        "    check_corrupted_images(image_dir)\n",
        "\n",
        "    # Step 3: Validate image dimensions\n",
        "    print(\"\\nValidating image dimensions...\")\n",
        "    validate_image_dimensions(image_dir, expected_size=(32, 32))\n",
        "\n",
        "    # Step 4: Validate color mode\n",
        "    print(\"\\nValidating image color mode...\")\n",
        "    validate_color_mode(image_dir, expected_mode='RGB')\n",
        "\n",
        "    # Step 5: Detect outliers by file size\n",
        "    print(\"\\nDetecting outliers by file size...\")\n",
        "    detect_outliers_by_size(image_dir)\n",
        "\n",
        "# Run the validation on your image dataset\n",
        "validate_image_dataset(IMAGE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCbgKktE_vU8",
        "outputId": "602547ec-df98-4cc7-fb2c-428a6258f2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting image dataset validation...\n",
            "\n",
            "Validating file types...\n",
            "All files have valid image extensions.\n",
            "\n",
            "Checking for corrupted files...\n",
            "No corrupted files found.\n",
            "\n",
            "Validating image dimensions...\n",
            "All images have the expected dimensions of (32, 32).\n",
            "\n",
            "Validating image color mode...\n",
            "All images have the expected color mode: RGB.\n",
            "\n",
            "Detecting outliers by file size...\n",
            "No outliers detected based on file size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# Simulating Negative Test Cases\n",
        "def simulate_negative_tests(image_dir):\n",
        "    # 1. Create a corrupted image\n",
        "    corrupted_image_path = os.path.join(image_dir, 'corrupted_image.jpg')\n",
        "    with open(corrupted_image_path, 'w') as f:\n",
        "        f.write(\"This is not a valid image file!\")\n",
        "\n",
        "    # 2. Create a non-image file with an image extension\n",
        "    invalid_file_path = os.path.join(image_dir, 'invalid_image.txt')\n",
        "    with open(invalid_file_path, 'w') as f:\n",
        "        f.write(\"This is a text file with an image extension!\")\n",
        "\n",
        "    # 3. Create an image with incorrect dimensions\n",
        "    img = Image.new('RGB', (100, 100), color='red')  # 100x100, not 32x32\n",
        "    img.save(os.path.join(image_dir, 'wrong_dimension_image.png'))\n",
        "\n",
        "    # 4. Create a grayscale image instead of RGB\n",
        "    img = Image.new('L', (32, 32), color=128)  # 'L' mode for grayscale\n",
        "    img.save(os.path.join(image_dir, 'grayscale_image.png'))\n",
        "\n",
        "    # 5. Add an extremely large image (outlier in size)\n",
        "    img = Image.new('RGB', (1000, 1000), color='blue')  # Abnormally large image\n",
        "    img.save(os.path.join(image_dir, 'large_image.png'))\n",
        "\n",
        "\n",
        "# Create negative test images\n",
        "simulate_negative_tests('cifar10_images')\n",
        "\n",
        "# Updated validation functions (with negative test handling)\n",
        "def validate_file_types(image_dir, valid_extensions=['.jpg', '.png']):\n",
        "    invalid_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        ext = os.path.splitext(filename)[-1].lower()\n",
        "        if ext not in valid_extensions:\n",
        "            invalid_files.append(filename)\n",
        "    if invalid_files:\n",
        "        print(f\"Invalid file types found: {invalid_files}\")\n",
        "    else:\n",
        "        print(\"All files have valid image extensions.\")\n",
        "\n",
        "\n",
        "def check_corrupted_images(image_dir):\n",
        "    corrupted_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Check if the image is corrupted\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            corrupted_files.append(filename)\n",
        "    if corrupted_files:\n",
        "        print(f\"Corrupted files found: {corrupted_files}\")\n",
        "    else:\n",
        "        print(\"No corrupted files found.\")\n",
        "\n",
        "\n",
        "def validate_image_dimensions(image_dir, expected_size=(32, 32)):\n",
        "    incorrect_size_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.size != expected_size:\n",
        "                    incorrect_size_files.append((filename, img.size))\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    if incorrect_size_files:\n",
        "        print(f\"Images with incorrect dimensions found: {incorrect_size_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected dimensions of {expected_size}.\")\n",
        "\n",
        "\n",
        "def validate_color_mode(image_dir, expected_mode='RGB'):\n",
        "    incorrect_mode_files = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                if img.mode != expected_mode:\n",
        "                    incorrect_mode_files.append((filename, img.mode))\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    if incorrect_mode_files:\n",
        "        print(f\"Images with incorrect color mode found: {incorrect_mode_files}\")\n",
        "    else:\n",
        "        print(f\"All images have the expected color mode: {expected_mode}.\")\n",
        "\n",
        "\n",
        "def detect_outliers_by_size(image_dir, threshold_factor=2):\n",
        "    sizes = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        sizes.append(os.path.getsize(file_path))\n",
        "\n",
        "    avg_size = np.mean(sizes)\n",
        "    std_dev = np.std(sizes)\n",
        "\n",
        "    outliers = [(filename, size) for filename, size in zip(os.listdir(image_dir), sizes) if abs(size - avg_size) > threshold_factor * std_dev]\n",
        "    if outliers:\n",
        "        print(f\"Outliers found based on size: {outliers}\")\n",
        "    else:\n",
        "        print(\"No outliers detected based on file size.\")\n",
        "\n",
        "\n",
        "# Main function to perform all validation steps, including negative tests\n",
        "def validate_image_dataset(image_dir):\n",
        "    print(\"Starting image dataset validation...\\n\")\n",
        "\n",
        "    # Step 1: Validate file types\n",
        "    print(\"Validating file types...\")\n",
        "    validate_file_types(image_dir)\n",
        "\n",
        "    # Step 2: Check for corrupted files\n",
        "    print(\"\\nChecking for corrupted files...\")\n",
        "    check_corrupted_images(image_dir)\n",
        "\n",
        "    # Step 3: Validate image dimensions\n",
        "    print(\"\\nValidating image dimensions...\")\n",
        "    validate_image_dimensions(image_dir, expected_size=(32, 32))\n",
        "\n",
        "    # Step 4: Validate color mode\n",
        "    print(\"\\nValidating image color mode...\")\n",
        "    validate_color_mode(image_dir, expected_mode='RGB')\n",
        "\n",
        "    # Step 5: Detect outliers by file size\n",
        "    print(\"\\nDetecting outliers by file size...\")\n",
        "    detect_outliers_by_size(image_dir)\n",
        "\n",
        "\n",
        "# Run the validation on the dataset with negative test cases\n",
        "validate_image_dataset('cifar10_images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVPPtgT9_zXr",
        "outputId": "9aa54b7b-ffef-46fa-d584-aecbe90423a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting image dataset validation...\n",
            "\n",
            "Validating file types...\n",
            "Invalid file types found: ['invalid_image.txt']\n",
            "\n",
            "Checking for corrupted files...\n",
            "Corrupted files found: ['invalid_image.txt', 'corrupted_image.jpg']\n",
            "\n",
            "Validating image dimensions...\n",
            "Images with incorrect dimensions found: [('large_image.png', (1000, 1000)), ('wrong_dimension_image.png', (100, 100))]\n",
            "\n",
            "Validating image color mode...\n",
            "Images with incorrect color mode found: [('grayscale_image.png', 'L')]\n",
            "\n",
            "Detecting outliers by file size...\n",
            "Outliers found based on size: [('large_image.png', 5213)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OJmCFR4iGVc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing an audio dataset for AI applications is a crucial step to ensure that the data used for model training and evaluation is of high quality, valid, and representative of the real-world scenarios the AI model will encounter. Proper validation of audio data involves multiple aspects, such as verifying the file types, checking for corruption, validating the duration of the audio files, and ensuring the data adheres to the expected format.\n",
        "\n",
        "**File Type and Corruption Checks:** The first step in audio dataset validation is to ensure that all files are in the correct format, such as `.wav`, `.mp3`, or another supported audio type. Corrupted files, which might contain incomplete or erroneous data, must also be identified and removed to prevent the model from learning incorrect patterns or failing during training.\n",
        "\n",
        "**Duration and Quality Validation:** Audio files should also be checked for duration, ensuring they fall within acceptable length ranges that are suitable for the AI model’s requirements. Extremely short or long files may not be useful or could introduce biases into the model. Quality measures, such as checking for noise or signal distortions, can also be essential depending on the use case.\n",
        "\n",
        "**Feature Integrity Checks:** In more advanced validation, you can inspect specific features extracted from audio, such as frequency, pitch, or spectrograms, to ensure the dataset covers a wide range of real-world scenarios. Tools like `librosa` or `pyDub` can help with these checks by loading and analyzing the audio files for features like amplitude, energy, and silence.\n",
        "\n",
        "Testing an audio dataset helps ensure that the data is not only valid and complete but also diverse and robust enough to allow the AI model to generalize well to new, unseen data. This validation minimizes the risk of model failure in production environments and ensures better performance."
      ],
      "metadata": {
        "id": "cXKhsHMGUvGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4j2kj_hUPjF",
        "outputId": "aaf4b508-fdbf-419a-be16-b551761ced0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# Create a smaller 'audio_dataset' directory if it doesn't exist\n",
        "audio_dir = 'small_audio_dataset'\n",
        "if not os.path.exists(audio_dir):\n",
        "    os.makedirs(audio_dir)\n",
        "\n",
        "# Simulate a small audio dataset with one negative case (corrupted file)\n",
        "def simulate_small_audio_tests(audio_dir):\n",
        "    # 1. Create a valid short audio file\n",
        "    sample_rate = 44100\n",
        "    duration = 2  # 2 seconds\n",
        "    audio_data = np.random.uniform(-1, 1, size=sample_rate * duration)\n",
        "    sf.write(os.path.join(audio_dir, 'valid_audio.wav'), audio_data, sample_rate)  # Use soundfile to write the file\n",
        "\n",
        "    # 2. Create a corrupted audio file\n",
        "    corrupted_audio_path = os.path.join(audio_dir, 'corrupted_audio.wav')\n",
        "    with open(corrupted_audio_path, 'w') as f:\n",
        "        f.write(\"This is not a valid audio file!\")\n",
        "\n",
        "# Create a small dataset with one valid file and one corrupted file\n",
        "simulate_small_audio_tests(audio_dir)\n",
        "\n",
        "# Validation Functions\n",
        "def validate_audio_file_types(audio_dir, valid_extensions=['.wav', '.mp3']):\n",
        "    invalid_files = []\n",
        "    for filename in os.listdir(audio_dir):\n",
        "        ext = os.path.splitext(filename)[-1].lower()\n",
        "        if ext not in valid_extensions:\n",
        "            invalid_files.append(filename)\n",
        "    if invalid_files:\n",
        "        print(f\"Invalid file types found: {invalid_files}\")\n",
        "    else:\n",
        "        print(\"All files have valid audio extensions.\")\n",
        "\n",
        "def check_corrupted_audio_files(audio_dir):\n",
        "    corrupted_files = []\n",
        "    for filename in os.listdir(audio_dir):\n",
        "        file_path = os.path.join(audio_dir, filename)\n",
        "        try:\n",
        "            librosa.load(file_path, sr=None)  # Try loading the file with librosa\n",
        "        except Exception as e:\n",
        "            corrupted_files.append(filename)\n",
        "    if corrupted_files:\n",
        "        print(f\"Corrupted audio files found: {corrupted_files}\")\n",
        "    else:\n",
        "        print(\"No corrupted audio files found.\")\n",
        "\n",
        "def validate_audio_duration(audio_dir, min_duration=1.0, max_duration=10.0):\n",
        "    incorrect_duration_files = []\n",
        "    for filename in os.listdir(audio_dir):\n",
        "        file_path = os.path.join(audio_dir, filename)\n",
        "        try:\n",
        "            audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "            duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
        "            if duration < min_duration or duration > max_duration:\n",
        "                incorrect_duration_files.append((filename, duration))\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    if incorrect_duration_files:\n",
        "        print(f\"Audio files with incorrect duration: {incorrect_duration_files}\")\n",
        "    else:\n",
        "        print(f\"All audio files are within the duration limits of {min_duration}s to {max_duration}s.\")\n",
        "\n",
        "# Main function to perform validation on the small dataset\n",
        "def validate_audio_dataset(audio_dir):\n",
        "    print(\"Starting small audio dataset validation...\\n\")\n",
        "\n",
        "    # Step 1: Validate file types\n",
        "    print(\"Validating file types...\")\n",
        "    validate_audio_file_types(audio_dir)\n",
        "\n",
        "    # Step 2: Check for corrupted files\n",
        "    print(\"\\nChecking for corrupted audio files...\")\n",
        "    check_corrupted_audio_files(audio_dir)\n",
        "\n",
        "    # Step 3: Validate audio duration\n",
        "    print(\"\\nValidating audio duration...\")\n",
        "    validate_audio_duration(audio_dir, min_duration=1.0, max_duration=10.0)\n",
        "\n",
        "# Run the validation on the small dataset\n",
        "validate_audio_dataset(audio_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tnt3GYJGWXT",
        "outputId": "3476e2c2-4254-41ec-b82b-96023046aaac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting small audio dataset validation...\n",
            "\n",
            "Validating file types...\n",
            "All files have valid audio extensions.\n",
            "\n",
            "Checking for corrupted audio files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1ce536a725c4>:44: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  librosa.load(file_path, sr=None)  # Try loading the file with librosa\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted audio files found: ['corrupted_audio.wav']\n",
            "\n",
            "Validating audio duration...\n",
            "All audio files are within the duration limits of 1.0s to 10.0s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1ce536a725c4>:57: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17OuAraYHmUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing a video dataset is an essential step in ensuring the quality and reliability of data for AI applications. This validation includes checking file integrity, consistency in frame rate and resolution, verifying metadata, and ensuring the accuracy of annotations and labels. Properly validating a video dataset can prevent issues during model training, reduce noise, and ensure that the AI model performs effectively in real-world scenarios."
      ],
      "metadata": {
        "id": "r5g3osCE1-Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def check_video_file(file_path):\n",
        "    video = cv2.VideoCapture(file_path)\n",
        "    if not video.isOpened():\n",
        "        print(f\"File {file_path} is corrupted or unsupported.\")\n",
        "    else:\n",
        "        print(f\"File {file_path} is valid.\")\n",
        "check_video_file('/content/Wildlife Windows 7 Sample Video.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIbOnFjf0FuQ",
        "outputId": "e6ac7de5-6986-4beb-ee05-80db8f242516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/Wildlife Windows 7 Sample Video.mp4 is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_frame_rate(file_path):\n",
        "    video = cv2.VideoCapture(file_path)\n",
        "    frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
        "    return frame_rate\n",
        "print( f\"Framme rate is {check_frame_rate('/content/Wildlife Windows 7 Sample Video.mp4')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOErcsY80GQU",
        "outputId": "a3731ff8-844b-4742-da43-d95849f6a7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Framme rate is 29.97002997002997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_resolution(file_path):\n",
        "    video = cv2.VideoCapture(file_path)\n",
        "    width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "    return width, height\n",
        "print( f\"resolution is {check_resolution('/content/Wildlife Windows 7 Sample Video.mp4')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_KKboso0JXi",
        "outputId": "f7a1efd6-5456-4fc0-a7ac-97bbe2f6df3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resolution is (640.0, 360.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def validate_video_dataset(video_dir):\n",
        "    for video_file in os.listdir(video_dir):\n",
        "        file_path = os.path.join(video_dir, video_file)\n",
        "\n",
        "        # Check file format\n",
        "        if not file_path.endswith(('.mp4', '.avi', '.mov')):\n",
        "            print(f\"Invalid format for {file_path}\")\n",
        "            continue\n",
        "\n",
        "        video = cv2.VideoCapture(file_path)\n",
        "\n",
        "        # Check if video is corrupted\n",
        "        if not video.isOpened():\n",
        "            print(f\"Cannot open video file {file_path}\")\n",
        "            continue\n",
        "\n",
        "        # Check frame rate\n",
        "        frame_rate = video.get(cv2.CAP_PROP_FPS)\n",
        "        if frame_rate < 24:  # Assume 24 FPS is the minimum acceptable frame rate\n",
        "            print(f\"Low frame rate: {frame_rate} for {file_path}\")\n",
        "\n",
        "        # Check resolution\n",
        "        width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "        height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "        if width < 640 or height < 480:  # Minimum resolution check\n",
        "            print(f\"Low resolution: {width}x{height} for {file_path}\")\n",
        "\n",
        "        # Check duration\n",
        "        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = frame_count / frame_rate\n",
        "        if duration < 1:  # Check for very short videos\n",
        "            print(f\"Short video duration: {duration} seconds for {file_path}\")\n",
        "\n",
        "        video.release()\n",
        "\n",
        "# Run the validation on your video dataset\n",
        "validate_video_dataset('/content')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qFHW0AY0Omk",
        "outputId": "b1da9aaa-6379-4cbf-e4cd-2e3b69ae7d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid format for /content/.config\n",
            "Low resolution: 640.0x360.0 for /content/Wildlife Windows 7 Sample Video.mp4\n",
            "Invalid format for /content/sample_data\n"
          ]
        }
      ]
    }
  ]
}